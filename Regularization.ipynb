{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:18:07.397532Z",
     "start_time": "2020-05-17T20:18:07.390187Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Freq_Regularization():\n",
    "    def predict_class(self, list_token_classes):\n",
    "        '''\n",
    "        UQA class = 0\n",
    "        LM class = 1\n",
    "        '''\n",
    "        if len(list_token_classes) == 0:\n",
    "            return np.random.choice(2, 1, p=[0.5, 0.5])[0]\n",
    "\n",
    "        prob_uqa = sum(list_token_classes)/len(list_token_classes)\n",
    "        prob_lm = 1 - prob_uqa\n",
    "        return np.random.choice(2, 1, p=[prob_uqa, prob_lm])[0]\n",
    "\n",
    "class Random_Regularization():\n",
    "    def predict_class(self):\n",
    "        '''\n",
    "        UQA class = 0\n",
    "        LM class = 1\n",
    "        '''\n",
    "        return np.random.choice(2, 1, p=[0.5, 0.5])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:18:07.790792Z",
     "start_time": "2020-05-17T20:18:07.740841Z"
    },
    "code_folding": [
     86,
     89
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (token_generation.py, line 338)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3319\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-11490715c89e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from BERTQG.token_generation import load_model, generate_token\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/workspace/UQA/BERTQG/token_generation.py\"\u001b[0;36m, line \u001b[0;32m338\u001b[0m\n\u001b[0;31m    banned_ids = tokenizer.convert_tokens_to_ids(['.', ',', \"'\", '\"', , ':', '(', ')', '?', '[SEP]'])\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from BERTQG.token_generation import load_model, generate_token\n",
    "from Regularization_module import Regularizer_Discriminator\n",
    "from itertools import groupby\n",
    "\n",
    "class QuestionGeneration():\n",
    "    def __init__(self, bert_model, lm_gq, uqa_qg, regularization=None):\n",
    "        self.lm_qg, _, _ = load_model(bert_model, lm_qg)\n",
    "        self.uqa_qg, self.tokenizer, self.device = load_model(bert_model, uqa_qg)\n",
    "#         self.regularization = Random_Regularization()\n",
    "        #self.regularization = Freq_Regularization()\n",
    "        self.regularization = Regularizer_Discriminator(regularization)\n",
    "        \n",
    "    def generate_question(self, context: str, ans: str, ans_start: str, wh_word: str, list_question_tokens: list = []) -> str:\n",
    "        '''\n",
    "        Input:\n",
    "            - context\n",
    "            - ans\n",
    "            - ans_start\n",
    "            - list_question_tokens: the history of generated question tokens. This is given for testing.\n",
    "            The form of list_question_tokens is a list of (q_token, class), where class is 0 for uqa\n",
    "            token and 1 for lm token\n",
    "        Output:\n",
    "            - The next generated question token\n",
    "        '''\n",
    "        # contains the tokens of the generated question\n",
    "        if len(list_question_tokens) == 0:\n",
    "            list_question_tokens = []\n",
    "            list_token_classes = [] # 0 = UQA, 1 = LM\n",
    "            list_qi_idx = [] \n",
    "            list_qi_probs = []\n",
    "        else: # for testing\n",
    "            len_initial_tokens = len(list_question_tokens)\n",
    "            list_token_classes = [-1] * len_initial_tokens # 0 = UQA, 1 = LM\n",
    "            list_qi_idx = [-1] * len_initial_tokens\n",
    "            list_qi_probs = [-1] * len_initial_tokens\n",
    "\n",
    "        # contains the classes of each token of the gen. question. Same len as list_question_tokens\n",
    "        qi = qi_idx = qi_probs = None\n",
    "        max_legnth = 50\n",
    "        # generation finished when [SEP] is created\n",
    "        while not self.__finished_generation(qi):\n",
    "            question_text = \" \".join(list_question_tokens).replace(' ##', '')\n",
    "            \n",
    "            # Get token class to use\n",
    "            # random\n",
    "#             qi_class = self.regularization.predict_class()\n",
    "\n",
    "            # freq\n",
    "            # qi_class = self.regularization.predict_class(list_token_classes)\n",
    "            \n",
    "            # disc\n",
    "            qi_class= self.regularization.predict_class(context,ans,ans_start,question_text,list_question_tokens)\n",
    "            \n",
    "            # Get the predicted token\n",
    "            # Generate the toknes and probs of the ith query token using the lm and uqa models\n",
    "            # penalize repetition token inside QG (need to input question history: list_qi_idx)\n",
    "            if qi_class == 1: # LM\n",
    "                qi, qi_idx, qi_probs = generate_token(self.lm_qg, self.tokenizer, self.device, wh_word, list_qi_idx, context, question_text, ans, ans_start)\n",
    "            else: # UQA\n",
    "                qi, qi_idx, qi_probs = generate_token(self.uqa_qg, self.tokenizer, self.device, wh_word, list_qi_idx, context, question_text, ans, ans_start)\n",
    "    \n",
    "            list_question_tokens.append(qi)\n",
    "            list_token_classes.append(qi_class)\n",
    "            list_qi_idx.append(qi_idx)\n",
    "            list_qi_probs.append(qi_probs)\n",
    "            \n",
    "            if (len(list_question_tokens) > max_legnth):\n",
    "                break\n",
    "        \n",
    "        # indices to keep\n",
    "        list_idx = self.__remove_consecutive_repeated_tokens(list_question_tokens)\n",
    "\n",
    "        # without [SEP] -> [:-1]\n",
    "        list_question_tokens = [list_question_tokens[idx] for idx in list_idx][:-1]\n",
    "        list_token_classes = [list_token_classes[idx] for idx in list_idx][:-1]\n",
    "        list_qi_idx = [list_qi_idx[idx] for idx in list_idx][:-1]\n",
    "        list_qi_probs = [list_qi_probs[idx] for idx in list_idx][:-1]\n",
    "        \n",
    "        assert len(list_question_tokens) == len(list_token_classes) == len(list_qi_idx) == len(list_qi_probs)\n",
    "\n",
    "        return \" \".join(list_question_tokens), list_token_classes, list_qi_idx, list_qi_probs\n",
    "            \n",
    "    def __finished_generation(self, question_token):\n",
    "        return question_token =='[SEP]'\n",
    "      \n",
    "    def __remove_consecutive_repeated_tokens(self, list_tokens):\n",
    "        '''\n",
    "        Removes consecutive tokens.\n",
    "        Sometimes the generated question is \"when when did...\",\n",
    "        so we need to remove one when\n",
    "        Output:\n",
    "            - list of index that is not consecutive repeated\n",
    "            - list of index to keep\n",
    "        '''\n",
    "        indices = range(len(list_tokens))\n",
    "        return [list(group)[0][1] for key, group in groupby(zip(list_tokens, indices), lambda x: x[0])]\n",
    "#     assert __remove_consecutive_repeated_tokens([1,1,1,1,1,1,2,3,4,4,5,1,2]) == [0, 6, 7, 8, 10, 11, 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:57:36.366830Z",
     "start_time": "2020-05-14T07:57:16.088479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2020 07:57:16 - INFO - BERTQG.tokenization -   loading vocabulary file BERTQG/models/bert-base-uncased/vocab.txt\n",
      "05/14/2020 07:57:22 - INFO - BERTQG.modeling -   loading archive file BERTQG/models/bert-base-uncased\n",
      "05/14/2020 07:57:22 - INFO - BERTQG.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 3,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERTQG/models/lm_10k_QG/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2020 07:57:24 - INFO - BERTQG.tokenization -   loading vocabulary file BERTQG/models/bert-base-uncased/vocab.txt\n",
      "05/14/2020 07:57:27 - INFO - BERTQG.modeling -   loading archive file BERTQG/models/bert-base-uncased\n",
      "05/14/2020 07:57:27 - INFO - BERTQG.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 3,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERTQG/models/uqa_10k_QG/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2020 07:57:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/14/2020 07:57:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/14/2020 07:57:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/14/2020 07:57:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/14/2020 07:57:31 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model = 'BERTQG/models/bert-base-uncased'\n",
    "lm_qg = 'BERTQG/models/lm_10k_QG/pytorch_model.bin'\n",
    "uqa_qg = 'BERTQG/models/uqa_10k_QG/pytorch_model.bin'\n",
    "regul_model = 'models/discri_model_partial_perturb.bin' # model path here\n",
    "#QG = QuestionGeneration(bert_model, lm_qg, uqa_qg)\n",
    "QG = QuestionGeneration(bert_model, lm_qg, uqa_qg, regul_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:21.751350Z",
     "start_time": "2020-05-11T16:05:21.748508Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "context = \"The city has a proud history of theatre. Stephen Kemble of the famous Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen years (1791–1806). He brought members of his famous acting family such as Sarah Siddons and John Kemble out of London to Newcastle. Stephen Kemble guided the theatre through many celebrated seasons. The original Theatre Royal in Newcastle was opened on 21 January 1788 and was located on Mosley Street. It was demolished to make way for Grey Street, where its replacement was built.\"\n",
    "# question_text = \"when did the original theatre royal open ?\"\n",
    "ans = \"1788\"\n",
    "ans_start = context.find(ans)\n",
    "assert context[ans_start:ans_start+len(ans)] == ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.036444Z",
     "start_time": "2020-05-11T16:05:21.753173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "question, history, indices, probs = QG.generate_question(context, ans, ans_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.041711Z",
     "start_time": "2020-05-11T16:05:25.038555Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when did the original theatre royal open on 21 january ?'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.112073Z",
     "start_time": "2020-05-11T16:05:25.043097Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.187083Z",
     "start_time": "2020-05-11T16:05:25.117847Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2043, 2106, 1996, 2434, 3004, 2548, 2330, 2006, 2538, 2254, 1029]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.261998Z",
     "start_time": "2020-05-11T16:05:25.192741Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00454629585146904"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[-1][102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:27.313778Z",
     "start_time": "2020-05-11T16:05:27.305731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_top_k(probs, k):\n",
    "    top_k_indices = [np.argsort(-np.array(probs[token_idx]))[:k].tolist() for token_idx in range(len(probs))]\n",
    "    top_k_probs = [sorted(probs[token_idx], reverse=True)[:k] for token_idx in range(len(probs))]\n",
    "    return top_k_indices, top_k_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:29.206113Z",
     "start_time": "2020-05-11T16:05:29.122973Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1029, 1012, 13739, 1010, 2960, 15622, 13393, 1024, 2997, 1011]\n",
      "[0.6433014273643494, 0.10247533023357391, 0.03994838520884514, 0.027439186349511147, 0.025517335161566734, 0.02007225900888443, 0.007837814278900623, 0.007773424033075571, 0.006851928308606148, 0.005206955596804619]\n"
     ]
    }
   ],
   "source": [
    "top_k_indices, top_k_probs = get_top_k(probs, 10)\n",
    "print(top_k_indices[-1])\n",
    "print(top_k_probs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:59:20.729665Z",
     "start_time": "2020-05-11T15:58:02.095178Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "k = 10\n",
    "for i in range(1000):\n",
    "    top_k_indices, top_k_probs = get_top_k(probs, k)\n",
    "    assert len(question.split()) == len(top_k_indices) == len(top_k_probs)\n",
    "    paragraph = {\n",
    "                'qid': i,\n",
    "                'context': context,\n",
    "                'question': question,\n",
    "                'top_k_indices': top_k_indices,\n",
    "                'top_k_probs': top_k_probs,\n",
    "                'answers': ans,\n",
    "                'answer_start': ans_start\n",
    "                }\n",
    "    output.append(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:12:49.505706Z",
     "start_time": "2020-05-11T15:12:49.497506Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:13:10.255688Z",
     "start_time": "2020-05-11T15:13:09.973995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('soft_target_test.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:22.090090Z",
     "start_time": "2020-05-13T05:34:21.754995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('data/UQA_finalQG_50k.json') as f:\n",
    "    UQA_finalQG_50k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:22.911498Z",
     "start_time": "2020-05-13T05:34:22.904296Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UQA_finalQG_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:24.192345Z",
     "start_time": "2020-05-13T05:34:24.184651Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'a5a90842b1c35606cdb2553f8ea14915864509ce',\n",
       " 'paragraphs': [{'context': 'Their first concert as a group was made at the closing party of Melbourne’s Spanish Club on 17 June 2007. Although barely announced, word that an alleged member of TISM was unveiling a new project led to a large, expectant crowd assembling. From there, word of mouth spread, leading to heavy traffic on the band\\'s nascent MySpace page, the creation of a fan website entitled The Root! Compendium, and growing demand for an album.The Root! Compendium - Archive - 17 June 2007. \"After the gig I managed to catch up with DC Root who claimed that a CD\\'s worth of material had been completed and was \"ready to go,\"\" - Review by Adam.',\n",
       "   'qas': [{'answers': [{'answer_start': 322, 'text': 'MySpace'}],\n",
       "     'question': 'What',\n",
       "     'NER_tag': 'ORG',\n",
       "     'id': 0}]}]}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UQA_finalQG_50k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:30.964668Z",
     "start_time": "2020-05-13T05:34:30.430012Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27b15d146cd43dc8c71c5a919ec9f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset refinement (whitespace tokenize)\n",
    "from transformers.tokenization_bert import whitespace_tokenize\n",
    "\n",
    "# refine whitespace and then reset answer_start\n",
    "for i in tqdm(range(len(UQA_finalQG_50k))):\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['context'] = \" \".join(whitespace_tokenize(UQA_finalQG_50k[i]['paragraphs'][0]['context']))\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text'] = \" \".join(whitespace_tokenize(UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text']))\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start'] = UQA_finalQG_50k[i]['paragraphs'][0]['context'].find(UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text'])\n",
    "    # only keep first answer\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'] = [UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:23:26.997753Z",
     "start_time": "2020-05-14T00:23:25.274604Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            'bert-base-uncased', do_lower_case=True, cache_dir=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:23:48.364847Z",
     "start_time": "2020-05-14T00:23:48.359015Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com', '#', '#', 'pen', '#', '#', 'di', '##um']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('com ##pen ##dium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:32.469160Z",
     "start_time": "2020-05-13T05:34:32.398056Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04e9a0307404766a85719e3355441e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for idx, article in enumerate(tqdm(UQA_finalQG_50k)):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:33.155312Z",
     "start_time": "2020-05-13T05:34:33.010362Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bbe9f1e4924c70bf995d80001dead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data check\n",
    "for idx, article in enumerate(tqdm(UQA_finalQG_50k)):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            context = paragraph['context']\n",
    "            ans = question['answers'][0]['text']\n",
    "            ans_start = question['answers'][0]['answer_start']\n",
    "#             print(idx, context[ans_start:ans_start+len(ans)], ans)\n",
    "            assert context[ans_start:ans_start+len(ans)] == ans\n",
    "            \n",
    "            start_position = ans_start\n",
    "            end_position = ans_start + len(ans)\n",
    "#             actual_text = \" \".join(context[start_position : (end_position + 1)])\n",
    "            actual_text = context[start_position : (end_position + 1)]\n",
    "            cleaned_answer_text = \" \".join(whitespace_tokenize(ans))\n",
    "\n",
    "            assert actual_text.find(cleaned_answer_text) != -1, (idx, actual_text, cleaned_answer_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:33:24.826334Z",
     "start_time": "2020-05-13T05:33:21.610386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('data/UQA_finalQG_50k_refined.json', 'w') as f:\n",
    "    json.dump(UQA_finalQG_50k, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset Generation with regularization (Soft-Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T08:13:55.488301Z",
     "start_time": "2020-05-14T08:13:55.115194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('data/UQA_finalQG_50k_refined.json') as f:\n",
    "    UQA_finalQG_50k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:55.219591Z",
     "start_time": "2020-05-13T05:34:55.214127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_top_k(probs, k):\n",
    "    top_k_indices = [np.argsort(-np.array(probs[token_idx]))[:k].tolist() for token_idx in range(len(probs))]\n",
    "    top_k_probs = [sorted(probs[token_idx], reverse=True)[:k] for token_idx in range(len(probs))]\n",
    "    return top_k_indices, top_k_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:30:25.990165Z",
     "start_time": "2020-05-13T05:37:25.516700Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8c527a351a4f6ebccc912aa458f3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_data = 10000\n",
    "output = []\n",
    "for article in tqdm(UQA_finalQG_50k[:num_data]):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            qid = question['id']\n",
    "            context = paragraph['context']\n",
    "            ans = question['answers'][0]['text']\n",
    "            ans_start = question['answers'][0]['answer_start']\n",
    "            wh_word = question['question']\n",
    "#             print('context:', context)\n",
    "#             print('ans:', ans)\n",
    "#             print('ans_start:', ans_start)\n",
    "            assert context[ans_start:ans_start+len(ans)] == ans\n",
    "\n",
    "            question, history, indices, probs = QG.generate_question(context, ans, ans_start, wh_word)\n",
    "#             print('question:', question.replace(' ##', ''))\n",
    "#             print('histroy:', history)\n",
    "#             print('indices:', indices)\n",
    "#             print('\\n')\n",
    "            top_k_indices, top_k_probs = get_top_k(probs, k)\n",
    "            assert len(question.split()) == len(top_k_indices) == len(top_k_probs)\n",
    "            paragraph = {\n",
    "                        'id': qid,\n",
    "                        'context': context,\n",
    "                        'question': question.replace(' ##', ''),\n",
    "                        'top_k_indices': top_k_indices,\n",
    "                        'top_k_probs': top_k_probs,\n",
    "                        'answers': ans,\n",
    "                        'answer_start': ans_start\n",
    "                        }\n",
    "            output.append(paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:44:35.380289Z",
     "start_time": "2020-05-14T00:44:31.577544Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('data/finalQG_train_10k.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of the united states has become a major exporter ?\n",
    "# question: what else is the purpose of the drug ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron ?\n",
    "# question: where were the first theories of logic in china and burma ?\n",
    "# question: when did environmental statement come from the environment of bp , bulwer island refinery ?\n",
    "# question: what is impersonating a girl in the movie ?\n",
    "# question: what was partly because of the influence of kaura mall ?\n",
    "# question: who was the presence of henderson and read the draft ?\n",
    "# question: what are some verbs that have a vowel change ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Generation for QA using Final QG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:18:41.317844Z",
     "start_time": "2020-05-17T20:18:40.491907Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('data/UQA_finalQG_100k_refined.json') as f:\n",
    "    UQA_finalQG_100k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:18:41.609409Z",
     "start_time": "2020-05-17T20:18:41.319294Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from BERTQG.token_generation import load_model, generate_token\n",
    "from itertools import groupby\n",
    "\n",
    "class QuestionGeneration():\n",
    "    def __init__(self, bert_model, final_gq):\n",
    "        self.final_qg, self.tokenizer, self.device = load_model(bert_model, final_qg)\n",
    "        \n",
    "    def generate_question(self, context: str, ans: str, ans_start: str, wh_word: str, list_question_tokens: list = []) -> str:\n",
    "        '''\n",
    "        Input:\n",
    "            - context\n",
    "            - ans\n",
    "            - ans_start\n",
    "            - list_question_tokens: the history of generated question tokens. This is given for testing.\n",
    "        Output:\n",
    "            - The next generated question token\n",
    "        '''\n",
    "        # contains the tokens of the generated question\n",
    "        if len(list_question_tokens) == 0:\n",
    "            list_question_tokens = []\n",
    "            list_qi_idx = [] \n",
    "            list_qi_probs = []\n",
    "        else: # for testing\n",
    "            len_initial_tokens = len(list_question_tokens)\n",
    "            list_qi_idx = [-1] * len_initial_tokens\n",
    "            list_qi_probs = [-1] * len_initial_tokens\n",
    "\n",
    "        # contains the classes of each token of the gen. question. Same len as list_question_tokens\n",
    "        qi = qi_idx = qi_probs = None\n",
    "        max_legnth = 50\n",
    "        # generation finished when [SEP] is created\n",
    "        while not self.__finished_generation(qi):\n",
    "            question_text = \" \".join(list_question_tokens).replace(' ##', '')\n",
    "            \n",
    "            qi, qi_idx, qi_probs = generate_token(self.final_qg, self.tokenizer, self.device, wh_word, list_qi_idx, context, question_text, ans, ans_start)\n",
    "    \n",
    "            list_question_tokens.append(qi)\n",
    "            list_qi_idx.append(qi_idx)\n",
    "            list_qi_probs.append(qi_probs)\n",
    "            \n",
    "            if (len(list_question_tokens) > max_legnth):\n",
    "                break\n",
    "        \n",
    "        # indices to keep\n",
    "        list_idx = self.__remove_consecutive_repeated_tokens(list_question_tokens)\n",
    "\n",
    "        # without [SEP] -> [:-1]\n",
    "        list_question_tokens = [list_question_tokens[idx] for idx in list_idx][:-1]\n",
    "        list_qi_idx = [list_qi_idx[idx] for idx in list_idx][:-1]\n",
    "        list_qi_probs = [list_qi_probs[idx] for idx in list_idx][:-1]\n",
    "        \n",
    "        assert len(list_question_tokens) == len(list_qi_idx) == len(list_qi_probs)\n",
    "\n",
    "        return \" \".join(list_question_tokens), list_qi_idx, list_qi_probs\n",
    "            \n",
    "    def __finished_generation(self, question_token):\n",
    "        return question_token =='[SEP]'\n",
    "      \n",
    "    def __remove_consecutive_repeated_tokens(self, list_tokens):\n",
    "        '''\n",
    "        Removes consecutive tokens.\n",
    "        Sometimes the generated question is \"when when did...\",\n",
    "        so we need to remove one when\n",
    "        Output:\n",
    "            - list of index that is not consecutive repeated\n",
    "            - list of index to keep\n",
    "        '''\n",
    "        indices = range(len(list_tokens))\n",
    "        return [list(group)[0][1] for key, group in groupby(zip(list_tokens, indices), lambda x: x[0])]\n",
    "#     assert __remove_consecutive_repeated_tokens([1,1,1,1,1,1,2,3,4,4,5,1,2]) == [0, 6, 7, 8, 10, 11, 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:19:06.232870Z",
     "start_time": "2020-05-17T20:19:03.133481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 20:19:03 - INFO - BERTQG.tokenization -   loading vocabulary file BERTQG/models/bert-base-uncased/vocab.txt\n",
      "05/17/2020 20:19:04 - INFO - BERTQG.modeling -   loading archive file BERTQG/models/bert-base-uncased\n",
      "05/17/2020 20:19:04 - INFO - BERTQG.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 3,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERTQG/models/finalQG_train_10k/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "bert_model = 'BERTQG/models/bert-base-uncased'\n",
    "final_qg = 'BERTQG/models/finalQG_train_10k/pytorch_model.bin'\n",
    "Final_QG = QuestionGeneration(bert_model, final_qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T20:19:11.458057Z",
     "start_time": "2020-05-17T20:19:06.234225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a35db71207a4fb087970d28134f715d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: who saw the was a catholic of england and did not see that taxes were due ?\n",
      "question: what was photography of the photograph is that you were a photographer did it ?\n",
      "question: what arrived at camp pendleton was the 1st marine division of army ?\n",
      "question: what else is called the people of labrador and are they have a language that means \"\n",
      "question: who is drew kirk and paul mcclain - a friend of the other two ?\n",
      "question: what are there in the united states that have been killed by black bears living ?\n",
      "question: what game was the best time you earned three assists in a series of games ?\n",
      "question: who is the keyser sozet of a bus that you ride ?\n",
      "question: who is the author of this poem was a poet in his poetry ?\n",
      "question: where are corncobs found in the andes of chile and bolivia ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_data = 100000\n",
    "output = {'data': [], 'version': 'v1.1'}\n",
    "for article in tqdm(UQA_finalQG_100k[10000:10010]):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            qid = question['id']\n",
    "            context = paragraph['context']\n",
    "            ans = question['answers'][0]['text']\n",
    "            ans_start = question['answers'][0]['answer_start']\n",
    "            wh_word = question['question']\n",
    "#             print('context:', context)\n",
    "#             print('ans:', ans)\n",
    "#             print('ans_start:', ans_start)\n",
    "            assert context[ans_start:ans_start+len(ans)] == ans\n",
    "\n",
    "            question, indices, probs = Final_QG.generate_question(context, ans, ans_start, wh_word)\n",
    "            print('question:', question.replace(' ##', ''))\n",
    "#             print('indices:', indices)\n",
    "#             print('\\n')\n",
    "\n",
    "            # SQuAD Format\n",
    "            paragraph = {'title': 'title',\n",
    "                         'paragraphs': [{'context': context, \n",
    "                         'qas': [{'question': question.replace(' ##', ''),\n",
    "                                 'id': qid, \n",
    "                                  'answers': [{'text': ans, 'answer_start': ans_start}]\n",
    "                                 }]}]}\n",
    "            output['data'].append(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:00:06.239787Z",
     "start_time": "2020-05-14T11:31:05.102Z"
    }
   },
   "outputs": [],
   "source": [
    "output['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T17:19:49.262660Z",
     "start_time": "2020-05-17T17:19:46.271886Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/finalQG_dev_100k.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
