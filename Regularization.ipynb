{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T03:13:43.804806Z",
     "start_time": "2020-05-13T03:13:43.797982Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Freq_Regularization():\n",
    "    def predict_class(self, list_token_classes):\n",
    "        '''\n",
    "        UQA class = 0\n",
    "        LM class = 1\n",
    "        '''\n",
    "        if len(list_token_classes) == 0:\n",
    "            return np.random.choice(2, 1, p=[0.5, 0.5])[0]\n",
    "\n",
    "        prob_uqa = sum(list_token_classes)/len(list_token_classes)\n",
    "        prob_lm = 1 - prob_uqa\n",
    "        return np.random.choice(2, 1, p=[prob_uqa, prob_lm])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T03:13:46.378117Z",
     "start_time": "2020-05-13T03:13:44.331613Z"
    },
    "code_folding": [
     86,
     89
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 03:13:44 - INFO - transformers.file_utils -   PyTorch version 1.4.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 03:13:46 - INFO - transformers.file_utils -   TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from BERTQG.token_generation import load_model, generate_token\n",
    "from Regularization_module import Regularizer_Discriminator\n",
    "from itertools import groupby\n",
    "\n",
    "class QuestionGeneration():\n",
    "    def __init__(self, bert_model, lm_gq, uqa_qg, regularization=None):\n",
    "        self.lm_qg, _, _ = load_model(bert_model, lm_qg)\n",
    "        self.uqa_qg, self.tokenizer, self.device = load_model(bert_model, uqa_qg)\n",
    "        #self.regularization = Freq_Regularization()\n",
    "        self.regularization = Regularizer_Discriminator(regularization)\n",
    "        \n",
    "    def generate_question(self, context: str, ans: str, ans_start: str, wh_word: str, list_question_tokens: list = []) -> str:\n",
    "        '''\n",
    "        Input:\n",
    "            - context\n",
    "            - ans\n",
    "            - ans_start\n",
    "            - list_question_tokens: the history of generated question tokens. This is given for testing.\n",
    "            The form of list_question_tokens is a list of (q_token, class), where class is 0 for uqa\n",
    "            token and 1 for lm token\n",
    "        Output:\n",
    "            - The next generated question token\n",
    "        '''\n",
    "        # contains the tokens of the generated question\n",
    "        if len(list_question_tokens) == 0:\n",
    "            list_question_tokens = []\n",
    "            list_token_classes = [] # 0 = UQA, 1 = LM\n",
    "            list_qi_idx = [] \n",
    "            list_qi_probs = []\n",
    "        else: # for testing\n",
    "            len_initial_tokens = len(list_question_tokens)\n",
    "            list_token_classes = [-1] * len_initial_tokens # 0 = UQA, 1 = LM\n",
    "            list_qi_idx = [-1] * len_initial_tokens\n",
    "            list_qi_probs = [-1] * len_initial_tokens\n",
    "\n",
    "        # contains the classes of each token of the gen. question. Same len as list_question_tokens\n",
    "        qi = qi_idx = qi_probs = None\n",
    "        max_legnth = 50\n",
    "        # generation finished when [SEP] is created\n",
    "        while not self.__finished_generation(qi):\n",
    "            question_text = \" \".join(list_question_tokens).replace(' ##', '')\n",
    "            \n",
    "            # Get token class to use\n",
    "            # qi_class = self.regularization.predict_class(list_token_classes)\n",
    "            qi_class= self.regularization.predict_class(context,ans,ans_start,question_text,list_question_tokens)\n",
    "            \n",
    "            # Get the predicted token\n",
    "            # Generate the toknes and probs of the ith query token using the lm and uqa models\n",
    "            # penalize repetition token inside QG (need to input question history: list_qi_idx)\n",
    "            if qi_class == 1: # LM\n",
    "                qi, qi_idx, qi_probs = generate_token(self.lm_qg, self.tokenizer, self.device, wh_word, list_qi_idx, context, question_text, ans, ans_start)\n",
    "            else: # UQA\n",
    "                qi, qi_idx, qi_probs = generate_token(self.uqa_qg, self.tokenizer, self.device, wh_word, list_qi_idx, context, question_text, ans, ans_start)\n",
    "    \n",
    "            list_question_tokens.append(qi)\n",
    "            list_token_classes.append(qi_class)\n",
    "            list_qi_idx.append(qi_idx)\n",
    "            list_qi_probs.append(qi_probs)\n",
    "            \n",
    "            if (len(list_question_tokens) > max_legnth):\n",
    "                break\n",
    "        \n",
    "        # indices to keep\n",
    "        list_idx = self.__remove_consecutive_repeated_tokens(list_question_tokens)\n",
    "\n",
    "        # without [SEP] -> [:-1]\n",
    "        list_question_tokens = [list_question_tokens[idx] for idx in list_idx][:-1]\n",
    "        list_token_classes = [list_token_classes[idx] for idx in list_idx][:-1]\n",
    "        list_qi_idx = [list_qi_idx[idx] for idx in list_idx][:-1]\n",
    "        list_qi_probs = [list_qi_probs[idx] for idx in list_idx][:-1]\n",
    "        \n",
    "        assert len(list_question_tokens) == len(list_token_classes) == len(list_qi_idx) == len(list_qi_probs)\n",
    "\n",
    "        return \" \".join(list_question_tokens), list_token_classes, list_qi_idx, list_qi_probs\n",
    "            \n",
    "    def __finished_generation(self, question_token):\n",
    "        return question_token =='[SEP]'\n",
    "      \n",
    "    def __remove_consecutive_repeated_tokens(self, list_tokens):\n",
    "        '''\n",
    "        Removes consecutive tokens.\n",
    "        Sometimes the generated question is \"when when did...\",\n",
    "        so we need to remove one when\n",
    "        Output:\n",
    "            - list of index that is not consecutive repeated\n",
    "            - list of index to keep\n",
    "        '''\n",
    "        indices = range(len(list_tokens))\n",
    "        return [list(group)[0][1] for key, group in groupby(zip(list_tokens, indices), lambda x: x[0])]\n",
    "#     assert __remove_consecutive_repeated_tokens([1,1,1,1,1,1,2,3,4,4,5,1,2]) == [0, 6, 7, 8, 10, 11, 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T03:13:57.580352Z",
     "start_time": "2020-05-13T03:13:48.016442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 03:13:48 - INFO - BERTQG.tokenization -   loading vocabulary file BERTQG/models/bert-base-uncased/vocab.txt\n",
      "05/13/2020 03:13:49 - INFO - BERTQG.modeling -   loading archive file BERTQG/models/bert-base-uncased\n",
      "05/13/2020 03:13:49 - INFO - BERTQG.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 3,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERTQG/models/lm_10k_QG/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 03:13:51 - INFO - BERTQG.tokenization -   loading vocabulary file BERTQG/models/bert-base-uncased/vocab.txt\n",
      "05/13/2020 03:13:51 - INFO - BERTQG.modeling -   loading archive file BERTQG/models/bert-base-uncased\n",
      "05/13/2020 03:13:51 - INFO - BERTQG.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 3,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BERTQG/models/uqa_10k_QG/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 03:13:53 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/13/2020 03:13:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/13/2020 03:13:54 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/13/2020 03:13:55 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/13/2020 03:13:55 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model = 'BERTQG/models/bert-base-uncased'\n",
    "lm_qg = 'BERTQG/models/lm_10k_QG/pytorch_model.bin'\n",
    "uqa_qg = 'BERTQG/models/uqa_10k_QG/pytorch_model.bin'\n",
    "regul_model = 'models/discri_model_partial_perturb.bin' # model path here\n",
    "#QG = QuestionGeneration(bert_model, lm_qg, uqa_qg)\n",
    "QG = QuestionGeneration(bert_model, lm_qg, uqa_qg, regul_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:21.751350Z",
     "start_time": "2020-05-11T16:05:21.748508Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "context = \"The city has a proud history of theatre. Stephen Kemble of the famous Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen years (1791–1806). He brought members of his famous acting family such as Sarah Siddons and John Kemble out of London to Newcastle. Stephen Kemble guided the theatre through many celebrated seasons. The original Theatre Royal in Newcastle was opened on 21 January 1788 and was located on Mosley Street. It was demolished to make way for Grey Street, where its replacement was built.\"\n",
    "# question_text = \"when did the original theatre royal open ?\"\n",
    "ans = \"1788\"\n",
    "ans_start = context.find(ans)\n",
    "assert context[ans_start:ans_start+len(ans)] == ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.036444Z",
     "start_time": "2020-05-11T16:05:21.753173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "question, history, indices, probs = QG.generate_question(context, ans, ans_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.041711Z",
     "start_time": "2020-05-11T16:05:25.038555Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when did the original theatre royal open on 21 january ?'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.112073Z",
     "start_time": "2020-05-11T16:05:25.043097Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.187083Z",
     "start_time": "2020-05-11T16:05:25.117847Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2043, 2106, 1996, 2434, 3004, 2548, 2330, 2006, 2538, 2254, 1029]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:25.261998Z",
     "start_time": "2020-05-11T16:05:25.192741Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00454629585146904"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[-1][102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:27.313778Z",
     "start_time": "2020-05-11T16:05:27.305731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_top_k(probs, k):\n",
    "    top_k_indices = [np.argsort(-np.array(probs[token_idx]))[:k].tolist() for token_idx in range(len(probs))]\n",
    "    top_k_probs = [sorted(probs[token_idx], reverse=True)[:k] for token_idx in range(len(probs))]\n",
    "    return top_k_indices, top_k_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T16:05:29.206113Z",
     "start_time": "2020-05-11T16:05:29.122973Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1029, 1012, 13739, 1010, 2960, 15622, 13393, 1024, 2997, 1011]\n",
      "[0.6433014273643494, 0.10247533023357391, 0.03994838520884514, 0.027439186349511147, 0.025517335161566734, 0.02007225900888443, 0.007837814278900623, 0.007773424033075571, 0.006851928308606148, 0.005206955596804619]\n"
     ]
    }
   ],
   "source": [
    "top_k_indices, top_k_probs = get_top_k(probs, 10)\n",
    "print(top_k_indices[-1])\n",
    "print(top_k_probs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:59:20.729665Z",
     "start_time": "2020-05-11T15:58:02.095178Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "k = 10\n",
    "for i in range(1000):\n",
    "    top_k_indices, top_k_probs = get_top_k(probs, k)\n",
    "    assert len(question.split()) == len(top_k_indices) == len(top_k_probs)\n",
    "    paragraph = {\n",
    "                'qid': i,\n",
    "                'context': context,\n",
    "                'question': question,\n",
    "                'top_k_indices': top_k_indices,\n",
    "                'top_k_probs': top_k_probs,\n",
    "                'answers': ans,\n",
    "                'answer_start': ans_start\n",
    "                }\n",
    "    output.append(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:12:49.505706Z",
     "start_time": "2020-05-11T15:12:49.497506Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T15:13:10.255688Z",
     "start_time": "2020-05-11T15:13:09.973995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('soft_target_test.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:22.090090Z",
     "start_time": "2020-05-13T05:34:21.754995Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('data/UQA_finalQG_50k.json') as f:\n",
    "    UQA_finalQG_50k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:22.911498Z",
     "start_time": "2020-05-13T05:34:22.904296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UQA_finalQG_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:24.192345Z",
     "start_time": "2020-05-13T05:34:24.184651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'a5a90842b1c35606cdb2553f8ea14915864509ce',\n",
       " 'paragraphs': [{'context': 'Their first concert as a group was made at the closing party of Melbourne’s Spanish Club on 17 June 2007. Although barely announced, word that an alleged member of TISM was unveiling a new project led to a large, expectant crowd assembling. From there, word of mouth spread, leading to heavy traffic on the band\\'s nascent MySpace page, the creation of a fan website entitled The Root! Compendium, and growing demand for an album.The Root! Compendium - Archive - 17 June 2007. \"After the gig I managed to catch up with DC Root who claimed that a CD\\'s worth of material had been completed and was \"ready to go,\"\" - Review by Adam.',\n",
       "   'qas': [{'answers': [{'answer_start': 322, 'text': 'MySpace'}],\n",
       "     'question': 'What',\n",
       "     'NER_tag': 'ORG',\n",
       "     'id': 0}]}]}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UQA_finalQG_50k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:30.964668Z",
     "start_time": "2020-05-13T05:34:30.430012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27b15d146cd43dc8c71c5a919ec9f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset refinement (whitespace tokenize)\n",
    "from transformers.tokenization_bert import whitespace_tokenize\n",
    "\n",
    "# refine whitespace and then reset answer_start\n",
    "for i in tqdm(range(len(UQA_finalQG_50k))):\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['context'] = \" \".join(whitespace_tokenize(UQA_finalQG_50k[i]['paragraphs'][0]['context']))\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text'] = \" \".join(whitespace_tokenize(UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text']))\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start'] = UQA_finalQG_50k[i]['paragraphs'][0]['context'].find(UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]['answers'][0]['text'])\n",
    "    # only keep first answer\n",
    "    UQA_finalQG_50k[i]['paragraphs'][0]['qas'] = [UQA_finalQG_50k[i]['paragraphs'][0]['qas'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:32.469160Z",
     "start_time": "2020-05-13T05:34:32.398056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04e9a0307404766a85719e3355441e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for idx, article in enumerate(tqdm(UQA_finalQG_50k)):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:33.155312Z",
     "start_time": "2020-05-13T05:34:33.010362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bbe9f1e4924c70bf995d80001dead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data check\n",
    "for idx, article in enumerate(tqdm(UQA_finalQG_50k)):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            context = paragraph['context']\n",
    "            ans = question['answers'][0]['text']\n",
    "            ans_start = question['answers'][0]['answer_start']\n",
    "#             print(idx, context[ans_start:ans_start+len(ans)], ans)\n",
    "            assert context[ans_start:ans_start+len(ans)] == ans\n",
    "            \n",
    "            start_position = ans_start\n",
    "            end_position = ans_start + len(ans)\n",
    "#             actual_text = \" \".join(context[start_position : (end_position + 1)])\n",
    "            actual_text = context[start_position : (end_position + 1)]\n",
    "            cleaned_answer_text = \" \".join(whitespace_tokenize(ans))\n",
    "\n",
    "            assert actual_text.find(cleaned_answer_text) != -1, (idx, actual_text, cleaned_answer_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:33:24.826334Z",
     "start_time": "2020-05-13T05:33:21.610386Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/UQA_finalQG_50k_refined.json', 'w') as f:\n",
    "    json.dump(UQA_finalQG_50k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:46.930566Z",
     "start_time": "2020-05-13T05:34:46.247252Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/UQA_finalQG_50k_refined.json') as f:\n",
    "    UQA_finalQG_50k = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T05:34:55.219591Z",
     "start_time": "2020-05-13T05:34:55.214127Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k(probs, k):\n",
    "    top_k_indices = [np.argsort(-np.array(probs[token_idx]))[:k].tolist() for token_idx in range(len(probs))]\n",
    "    top_k_probs = [sorted(probs[token_idx], reverse=True)[:k] for token_idx in range(len(probs))]\n",
    "    return top_k_indices, top_k_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-13T05:37:24.934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8c527a351a4f6ebccc912aa458f3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 10\n",
    "num_data = 10000\n",
    "output = []\n",
    "for article in tqdm(UQA_finalQG_50k[:num_data]):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for question in paragraph['qas']:\n",
    "            qid = question['id']\n",
    "            context = paragraph['context']\n",
    "            ans = question['answers'][0]['text']\n",
    "            ans_start = question['answers'][0]['answer_start']\n",
    "            wh_word = question['question']\n",
    "#             print('context:', context)\n",
    "#             print('ans:', ans)\n",
    "#             print('ans_start:', ans_start)\n",
    "            assert context[ans_start:ans_start+len(ans)] == ans\n",
    "\n",
    "            question, history, indices, probs = QG.generate_question(context, ans, ans_start, wh_word)\n",
    "#             print('question:', question.replace(' ##', ''))\n",
    "#             print('histroy:', history)\n",
    "#             print('indices:', indices)\n",
    "#             print('\\n')\n",
    "            top_k_indices, top_k_probs = get_top_k(probs, k)\n",
    "            assert len(question.split()) == len(top_k_indices) == len(top_k_probs)\n",
    "            paragraph = {\n",
    "                        'id': qid,\n",
    "                        'context': context,\n",
    "                        'question': question,\n",
    "                        'top_k_indices': top_k_indices,\n",
    "                        'top_k_probs': top_k_probs,\n",
    "                        'answers': ans,\n",
    "                        'answer_start': ans_start\n",
    "                        }\n",
    "            output.append(paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/finalQG_train_10k.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of the united states has become a major exporter ?\n",
    "# question: what else is the purpose of the drug ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron ?\n",
    "# question: where were the first theories of logic in china and burma ?\n",
    "# question: when did environmental statement come from the environment of bp , bulwer island refinery ?\n",
    "# question: what is impersonating a girl in the movie ?\n",
    "# question: what was partly because of the influence of kaura mall ?\n",
    "# question: who was the presence of henderson and read the draft ?\n",
    "# question: what are some verbs that have a vowel change ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of the united states ?\n",
    "# question: what else is the purpose of the drug that is being investigated ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron flows west through ?\n",
    "# question: where were the first theories of logic in china and burma ?\n",
    "# question: when did environmental statement come from the environment of bp , bulwer island refinery was released ?\n",
    "# question: what is impersonating a girl in the movie ?\n",
    "# question: what was partly because of the influence of kaura mall ?\n",
    "# question: who was the presence of henderson and read the draft ?\n",
    "# question: what are some verbs that have a vowel change in the form of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of the united states ?\n",
    "# question: what else is the purpose of the drug that is being investigated ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron flows west through ?\n",
    "# question: where were the first theories of logic in china and burma ?\n",
    "# question: when did environmental statement come from the environment of bp , bulwer island refinery was released ?\n",
    "# question: what is impersonating a girl in the movie ?\n",
    "# question: what was partly because of the influence of kaura mall ?\n",
    "# question: who was the presence of henderson and read the draft ?\n",
    "# question: what are some verbs that have a vowel change in the form of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of china ' s economy ?\n",
    "# question: what else is the purpose of the drug that is being investigated ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron flows west through ?\n",
    "# question: where were the first theories of logic in china and india ?\n",
    "# question: when did environmental statement come from the environment of bp , bulwer island refinery was released ?\n",
    "# question: what is impersonating a girl ' s best friend ?\n",
    "# question: what was partly because of the sikhs ' influence on ?\n",
    "# question: who was the presence of henderson ' s draft and ?\n",
    "# question: what are some verbs that have a vowel change in the form of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what is the traffic leading on the root ! compendium page ?\n",
    "# question: where is the new economic center of china ' s economy ?\n",
    "# question: what else is the purpose of the drug that is being investigated ?\n",
    "# question: where is flowing west through the commune of terron ?\n",
    "# question: what is flowing in the commune of terron , ?\n",
    "# question: where were the first theories of logic in china , ?\n",
    "# question: when did environmental statement , bulwer island refinery take place ?\n",
    "# question: what is impersonating a girl ' s best friend ?\n",
    "# question: what was partly because of the sikhs , they were not a ?\n",
    "# question: who was the presence of henderson , he read the draft ?\n",
    "# question: what are some verbs that have a vowel change in the form of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:01:48.933371Z",
     "start_time": "2020-05-12T18:01:48.883641Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k_indices, _ = get_top_k(probs, 10)\n",
    "# top_k_indices[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:05:28.903107Z",
     "start_time": "2020-05-12T18:05:28.898721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ru', '?', 'river', 'first', 'most', 'name', 'commune', 'who', 'other', 'one']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QG.tokenizer.convert_ids_to_tokens(top_k_indices[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question: what is the traffic leading what is the root ! com ##pen ##tagram ?\n",
    "    \n",
    "question: what is the traffic leading where did you get the idea that you are leading ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:35:39.159531Z",
     "start_time": "2020-05-12T16:35:39.153201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'a5a90842b1c35606cdb2553f8ea14915864509ce',\n",
       " 'paragraphs': [{'context': 'Their first concert as a group was made at the closing party of Melbourne’s Spanish Club on 17 June 2007. Although barely announced, word that an alleged member of TISM was unveiling a new project led to a large, expectant crowd assembling. From there, word of mouth spread, leading to heavy traffic on the band\\'s nascent MySpace page, the creation of a fan website entitled The Root! Compendium, and growing demand for an album.The Root! Compendium - Archive - 17 June 2007. \"After the gig I managed to catch up with DC Root who claimed that a CD\\'s worth of material had been completed and was \"ready to go,\"\" - Review by Adam.',\n",
       "   'qas': [{'answers': [{'answer_start': 322, 'text': 'MySpace'}],\n",
       "     'question': 'What',\n",
       "     'NER_tag': 'ORG',\n",
       "     'id': 0}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UQA_finalQG_50k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
